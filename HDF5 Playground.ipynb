{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this notebook I will be reading the book ['Python and HDF5, Unlocking Scientific Data'](http://shop.oreilly.com/product/0636920030249.do) and try implementing the code given in the book, either as is or modified to suit my understanding or try some new thing out. The notebook will be filled with a lot of code accompanied by comments mentioning some important concept, intuition. To finish the book faster and get as much content as possible in the notebook I won't be giving the background for the HDF5 file format and other high level theoretical details which can be found in the book or other pages online but focus more on practical aspect of coding in Python and using HDF5 for storing scientific data.\n",
    "\n",
    "The HDF5 web site can be found [here](https://support.hdfgroup.org/HDF5/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the an example of data collected from weather station. Suppose we have 10 weather stations numbered from 1 to 10 for a date 1-Jan-2017 and each of them record temperature in Fahrenheit and wind speed in mph. We assume the numbers are integers and not floating point numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = 1\n",
    "month = 'Jan'\n",
    "year = 2017\n",
    "\n",
    "station_ids = range(1, 11, 1)\n",
    "np.random.seed(0)\n",
    "temperatures = np.asarray([np.random.randint(60, 80) for _ in station_ids])\n",
    "wind_speeds = np.asarray([np.random.randint(0, 10) for _ in station_ids])\n",
    "\n",
    "with h5py.File('weather.hdf5', 'w') as f:\n",
    "    for station_id, temperature, wind_speed in zip(station_ids, temperatures, wind_speeds):        \n",
    "        temperature_key = '/' + str(station_id) + '/temperature'\n",
    "        f[temperature_key] = temperature\n",
    "        f[temperature_key].attrs['date'] = 1\n",
    "        f[temperature_key].attrs['month'] = month\n",
    "        f[temperature_key].attrs['year'] = year\n",
    "        wind_speed_key = '/' + str(station_id) + '/wind_speed'\n",
    "        f[wind_speed_key] = wind_speed\n",
    "        f[wind_speed_key].attrs['date'] = 1\n",
    "        f[wind_speed_key].attrs['month'] = month\n",
    "        f[wind_speed_key].attrs['year'] = year\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now open this file and retrieve readings of the station 7 and confirm its what we wrote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature at station 7 is 69 ,wind speed recorded is 7 , the date these measurements were taken is 1-Jan-2017\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('weather.hdf5') as f:\n",
    "    station7_temperature = f['/7/temperature']\n",
    "    station7_wind_speed = f['/7/wind_speed']\n",
    "    assert station7_temperature.value == temperatures[6], 'Value not same as the one written'\n",
    "    assert station7_wind_speed.value == wind_speeds[6], 'Value not same as the one written'\n",
    "    temperature_node_attrs = dict([a for a in station7_temperature.attrs.items()])\n",
    "    print('Temperature at station 7 is', station7_temperature.value, ',wind speed recorded is'\n",
    "          ,station7_wind_speed.value, ', the date these measurements were taken is',\n",
    "         '%d-%s-%d'%(temperature_node_attrs['date'], temperature_node_attrs['month'], temperature_node_attrs['year']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDF5 file is not entirely loaded in memory but only the data required and read is loaded. In above case the weathers file may have a lot of data but only the necessary information about station 7 was read in memory when requested\n",
    "\n",
    "Let's look at another example. where we create a dataset (we are yet to see what a dataset is).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the file BigArrayFile.hdf5 is 1400 bytes\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('BigArrayFile.hdf5', 'w') as f:\n",
    "    dataset = f.create_dataset('big', shape = (1024, 1024), dtype = 'float32')\n",
    "    \n",
    "stats = os.stat('BigArrayFile.hdf5')\n",
    "print('Size of the file BigArrayFile.hdf5 is',stats.st_size, 'bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see above, we created an HDF5 file and created a data set called big in it of shape $1024 \\times 1024$ of type float32. Yet, the size of the file on the disk is 1400 bytes, let us set a byte at index (2, 2) with value 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the file BigArrayFile.hdf5 is 4195704 bytes\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('BigArrayFile.hdf5') as f:\n",
    "    dataset = f['big']\n",
    "    dataset[2, 2] = 2.0\n",
    "    \n",
    "stats = os.stat('BigArrayFile.hdf5')\n",
    "print('Size of the file BigArrayFile.hdf5 is',stats.st_size, 'bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " As we see above, once we accessed the byte of the data set the entire dataset was flushed to the disk. The shape times 4 bytes(for float32) per location should take $1025 \\times 1024 \\times 8 = 4194304$, the size we see above is pretty close to this number as there HDF5 itself takes few bytes for the meta data. Also, an interesting point to note is that the dataset can be large in size (large enough to load all in memory), but only the bytes accessed will be loaded in memory.\n",
    " \n",
    " HDF5 also supports compression of the data. Lets create a dataset of same size $1024 \\times 1024$, but create the dataset using compression gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the file BigCompressedArrayFile.hdf5 is 4075 bytes\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('BigCompressedArrayFile.hdf5', 'w') as f:\n",
    "    dataset = f.create_dataset('big', shape = (1024, 1024), dtype = 'float32', compression = 'gzip')\n",
    "    dataset[2, 2] = 2.0\n",
    "    \n",
    "stats = os.stat('BigCompressedArrayFile.hdf5')\n",
    "print('Size of the file BigCompressedArrayFile.hdf5 is',stats.st_size, 'bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see above, the file containing the dataset with same shape, but compressed has a much lower size of the data stored on the disk. There is however a tradeoff between space on disk and CPU time required to compress and decompress the contents. We will talk more on this later in the notebook.\n",
    "\n",
    "We have used ``h5py.File`` to open the file. The second parameter is the ``mode`` argument which can either be\n",
    "\n",
    "* r  : read only for existing file, fails when the provided file is not present\n",
    "* r+ : read/write for existing file, fails when the provided file is not present\n",
    "* w  : write, create a new file, truncates an existing file\n",
    "* w- : write, same as w except that it doesnt truncate an existing file but the operation fails\n",
    "* a  : read/write, if existing file not found, new one will be created (this if not the same in case of r+)\n",
    "\n",
    "---\n",
    "\n",
    "TODO: Give some introduction on the type of drivers available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
